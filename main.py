from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import requests
import hashlib
import hmac
import base64
import time
from typing import List, Dict, Optional
from bs4 import BeautifulSoup
import json
import os
import traceback

app = FastAPI(title="Naver Crawler API", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API ì„¤ì • (ìƒˆ ê³„ì •)
NAVER_API_CUSTOMER_ID = os.getenv("NAVER_API_CUSTOMER_ID", "1978176")
NAVER_API_LICENSE = os.getenv("NAVER_API_LICENSE", "0100000000713f505bb5fda08833f32b6a9ae08c5ea5789f134c7b140446e58bdb4183fc1d")
NAVER_API_SECRET = os.getenv("NAVER_API_SECRET", "AQAAAABxP1Bbtf2giDPzK2qa4Ixetc774mZsCjCKxTp2BVV29g==")

# í™˜ê²½ ë³€ìˆ˜ ê²€ì¦ (ìƒì„¸)
print(f"=" * 60)
print(f"ğŸ”§ Environment Variables Check:")
print(f"  - CUSTOMER_ID: {NAVER_API_CUSTOMER_ID if NAVER_API_CUSTOMER_ID else 'âŒ NOT SET'}")
print(f"  - LICENSE: {NAVER_API_LICENSE[:20] + '...' if NAVER_API_LICENSE else 'âŒ NOT SET'}")
print(f"  - SECRET: {NAVER_API_SECRET[:20] + '...' if NAVER_API_SECRET else 'âŒ NOT SET'}")
print(f"  - PORT: {os.getenv('PORT', '8000')}")
print(f"=" * 60)

# í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½ ì‹œ ê²½ê³ 
if not NAVER_API_CUSTOMER_ID or not NAVER_API_LICENSE or not NAVER_API_SECRET:
    print("âš ï¸  WARNING: Some environment variables are missing!")
    print("âš ï¸  Please set all required variables in Railway dashboard.")

# ìš”ì²­ ëª¨ë¸
class SearchAnalysisRequest(BaseModel):
    keyword: str
    placeUrl: Optional[str] = None

class HealthResponse(BaseModel):
    status: str
    message: str

# ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API ì‹œê·¸ë‹ˆì²˜ ìƒì„±
def generate_signature(timestamp: str, method: str, uri: str) -> str:
    """ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API ì„œëª… ìƒì„±"""
    message = f"{timestamp}.{method}.{uri}"
    signature = hmac.new(
        NAVER_API_SECRET.encode('utf-8'),
        message.encode('utf-8'),
        hashlib.sha256
    ).digest()
    return base64.b64encode(signature).decode('utf-8')

# ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API í˜¸ì¶œ
def call_naver_api(keyword: str) -> Dict:
    """ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  APIë¡œ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ"""
    try:
        # ì§€ì—­ëª… ì œê±° (ì¸ì²œ, ì„œìš¸, ë¶€ì‚° ë“±)
        regions = ["ì¸ì²œ", "ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ëŒ€ì „", "ê´‘ì£¼", "ìš¸ì‚°", "ì„¸ì¢…", "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼",
                   "ì„œêµ¬", "ë¶êµ¬", "ë™êµ¬", "ë‚¨êµ¬", "ì¤‘êµ¬", "ì²­ë¼", "ê²€ë‹¨", "ì†¡ë„", "ê°•ë‚¨", "ê°•ë¶", "ì„œì´ˆ", "ì¢…ë¡œ", "ë§ˆí¬", "ê°•ì„œ", "í•´ìš´ëŒ€"]
        core_keyword = keyword
        for region in regions:
            core_keyword = core_keyword.replace(region + " ", "").replace(region, "")
        core_keyword = core_keyword.strip()
        
        print(f"ì›ë³¸ í‚¤ì›Œë“œ: {keyword} â†’ í•µì‹¬ í‚¤ì›Œë“œ: {core_keyword}")
        
        timestamp = str(int(time.time() * 1000))
        method = "GET"
        uri = "/keywordstool"
        
        signature = generate_signature(timestamp, method, uri)
        
        headers = {
            "X-Timestamp": timestamp,
            "X-API-KEY": NAVER_API_LICENSE,
            "X-Customer": NAVER_API_CUSTOMER_ID,
            "X-Signature": signature,
            "Content-Type": "application/json"
        }
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ API
        url = "https://api.naver.com/keywordstool"
        params = {
            "hintKeywords": core_keyword,  # í•µì‹¬ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
            "showDetail": "1"
        }
        
        print(f"ë„¤ì´ë²„ API í˜¸ì¶œ: {core_keyword}")
        
        response = requests.get(url, headers=headers, params=params, timeout=30)
        
        print(f"ì‘ë‹µ ì½”ë“œ: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            keywords = data.get("keywordList", [])
            if keywords:
                print(f"âœ… {len(keywords)}ê°œ í‚¤ì›Œë“œ ë°œê²¬")
                return {
                    "success": True,
                    "data": data
                }
            else:
                print("âš ï¸  í‚¤ì›Œë“œ ë°ì´í„° ì—†ìŒ")
                return {
                    "success": False,
                    "error": "í‚¤ì›Œë“œ ë°ì´í„° ì—†ìŒ"
                }
        else:
            print(f"API ì˜¤ë¥˜: {response.status_code} - {response.text}")
            return {
                "success": False,
                "error": f"API ì˜¤ë¥˜: {response.status_code}",
                "details": response.text
            }
    except Exception as e:
        print(f"API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e)
        }

# ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ìˆœìœ„ í¬ë¡¤ë§ (ê°œì„  ë²„ì „)
def crawl_place_ranking(keyword: str, target_url: Optional[str] = None) -> Dict:
    """ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ìˆœìœ„ í¬ë¡¤ë§ (BeautifulSoup + ê´‘ê³  ì œì™¸)"""
    try:
        print(f"ğŸ•·ï¸  í¬ë¡¤ë§ ì‹œì‘: {keyword}")
        
        # ë„¤ì´ë²„ í†µí•©ê²€ìƒ‰ ëª¨ë°”ì¼ API ì§ì ‘ í˜¸ì¶œ
        import urllib.parse
        encoded_keyword = urllib.parse.quote(keyword)
        
        # ë„¤ì´ë²„ ëª¨ë°”ì¼ ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€
        search_url = f"https://m.search.naver.com/search.naver?query={encoded_keyword}&sm=mtb_jum&where=m&oquery={encoded_keyword}&tqi=iWe9cdqo15wssZCVXMRsssssttR-215835"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Referer': 'https://m.naver.com/'
        }
        
        print(f"í¬ë¡¤ë§ URL: {search_url}")
        response = requests.get(search_url, headers=headers, timeout=30)
        print(f"ì‘ë‹µ ì½”ë“œ: {response.status_code}")
        
        if response.status_code != 200:
            print(f"âŒ HTTP {response.status_code} ì˜¤ë¥˜")
            return {
                "success": False,
                "myRank": None,
                "competitors": []
            }
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        places = []
        my_rank = None
        rank = 0
        
        # ì—¬ëŸ¬ ì„ íƒì íŒ¨í„´ ì‹œë„
        selectors = [
            'div.place_didyoumean ul li',
            'div.list_image_type ul li',
            'ul.list_search li',
            'div.api_subject_bx ul li',
            'div[class*="place"] ul li',
            'li[class*="place"]',
            'ul[class*="list"] > li'
        ]
        
        place_containers = []
        for selector in selectors:
            elements = soup.select(selector)
            if elements:
                print(f"âœ… ì„ íƒì '{selector}' - {len(elements)}ê°œ ë°œê²¬")
                place_containers = elements
                break
        
        if not place_containers:
            print("âš ï¸  í”Œë ˆì´ìŠ¤ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            # HTML êµ¬ì¡° ë¶„ì„ ì¶œë ¥
            print(f"HTML ê¸¸ì´: {len(response.text)} bytes")
            print(f"HTML ìƒ˜í”Œ:\n{response.text[:1000]}")
            
            # ëŒ€ì•ˆ: ê°„ë‹¨í•œ ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜
            return {
                "success": True,
                "myRank": None,
                "competitors": [
                    {"rank": 1, "name": "í¬ë¡¤ë§ ì œí•œ", "category": "ë„¤ì´ë²„ ë³´ì•ˆ", "reviewCount": 0, "url": ""},
                    {"rank": 2, "name": "ì‹¤ì œ ìˆœìœ„ëŠ”", "category": "ë¸Œë¼ìš°ì €ì—ì„œ", "reviewCount": 0, "url": ""},
                    {"rank": 3, "name": "í™•ì¸ ê°€ëŠ¥", "category": "ìˆ˜ë™ í™•ì¸", "reviewCount": 0, "url": ""}
                ]
            }
        
        print(f"ì´ {len(place_containers)}ê°œ í”Œë ˆì´ìŠ¤ ë°œê²¬")
        
        for idx, place in enumerate(place_containers[:20], 1):
            try:
                # ê´‘ê³  ì œì™¸
                ad_marker = place.select_one('.ad_marker, .ad, [class*="ad"], [class*="Ad"]')
                if ad_marker:
                    ad_classes = str(ad_marker.get('class', []))
                    if 'ad' in ad_classes.lower():
                        print(f"ê´‘ê³  ì œì™¸: {idx}")
                        continue
                
                rank += 1
                
                # ì—…ì²´ëª…
                name_elem = place.select_one('.place_bluelink, .YwYLL, span.place_name, strong.name, .tit, a.title')
                name = name_elem.get_text(strip=True) if name_elem else f"ì—…ì²´ {rank}"
                
                # ì¹´í…Œê³ ë¦¬
                category_elem = place.select_one('.category, .cate, .type, .KCMnt, .info_distance')
                category = category_elem.get_text(strip=True) if category_elem else "ì¼ë°˜"
                
                # ë¦¬ë·° ìˆ˜
                review_count = 0
                review_elem = place.select_one('.review_count, .cnt, em.num, .NSTUp, .review')
                if review_elem:
                    review_text = review_elem.get_text(strip=True)
                    numbers = ''.join(filter(str.isdigit, review_text))
                    review_count = int(numbers) if numbers else 0
                
                # URL
                link_elem = place.select_one('a[href*="place.naver.com"], a[href*="/place/"], a.place_bluelink, a.title')
                place_url = ""
                if link_elem:
                    href = link_elem.get('href', '')
                    if href.startswith('http'):
                        place_url = href
                    elif href.startswith('/'):
                        place_url = f"https://m.place.naver.com{href}"
                    else:
                        place_url = f"https://m.place.naver.com/{href}"
                
                place_info = {
                    "rank": rank,
                    "name": name,
                    "category": category,
                    "reviewCount": review_count,
                    "url": place_url
                }
                
                print(f"ìˆœìœ„ {rank}: {name} ({category}) - {review_count}ê°œ ë¦¬ë·°")
                
                places.append(place_info)
                
                # ë‚´ ìˆœìœ„ í™•ì¸
                if target_url and place_url and (target_url in place_url or place_url in target_url):
                    my_rank = rank
                    print(f"âœ… ë‚´ ìˆœìœ„ ë°œê²¬: {rank}ìœ„")
                
                # ìƒìœ„ 10ê°œë§Œ ìˆ˜ì§‘
                if rank >= 10:
                    break
                    
            except Exception as e:
                print(f"í”Œë ˆì´ìŠ¤ íŒŒì‹± ì˜¤ë¥˜ (idx={idx}): {str(e)}")
                continue
        
        print(f"âœ… ì´ {len(places)}ê°œ í”Œë ˆì´ìŠ¤ ì¶”ì¶œ ì™„ë£Œ")
        
        return {
            "success": True,
            "myRank": my_rank,
            "competitors": places[:10]
        }
        
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}")
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "myRank": None,
            "competitors": []
        }
        if driver:
            try:
                driver.quit()
                print("âœ… WebDriver ì •ìƒ ì¢…ë£Œ")
            except Exception as e:
                print(f"âš ï¸  WebDriver ì¢…ë£Œ ì˜¤ë¥˜: {str(e)}")

# ê²½ìŸì‚¬ í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_competitor_keywords(competitors: List[Dict]) -> List[Dict]:
    """ê²½ìŸì‚¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°œì„  ë²„ì „)"""
    result = []
    
    for comp in competitors[:5]:  # ìƒìœ„ 5ê°œ ê²½ìŸì‚¬ë§Œ
        keywords = []
        
        # ì—…ì²´ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        name = comp.get("name", "")
        category = comp.get("category", "")
        
        # ì—…ì²´ëª…ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        if "ì˜ì–´" in name or "ì˜ì–´" in category or "English" in name:
            keywords.extend(["ì˜ì–´í•™ì›", "ì˜ì–´êµìœ¡", "ì˜ì–´íšŒí™”", "í† ìµ", "í† í”Œ"])
        if "ìˆ˜í•™" in name or "ìˆ˜í•™" in category:
            keywords.extend(["ìˆ˜í•™í•™ì›", "ìˆ˜í•™êµìœ¡", "ìˆ˜í•™ì „ë¬¸", "ìˆ˜ëŠ¥ìˆ˜í•™"])
        if "êµ­ì–´" in name or "ë…¼ìˆ " in name:
            keywords.extend(["êµ­ì–´í•™ì›", "ë…¼ìˆ í•™ì›", "ë…ì„œë…¼ìˆ "])
        if "ê³¼í•™" in name:
            keywords.extend(["ê³¼í•™í•™ì›", "ê³¼í•™êµìœ¡"])
        if "í•™ì›" in name:
            keywords.append("ì¢…í•©í•™ì›")
        if "êµìŠµì†Œ" in name or "êµì‹¤" in name:
            keywords.append("êµìŠµì†Œ")
        if "ì•„ì¹´ë°ë¯¸" in name or "Academy" in name:
            keywords.append("ì•„ì¹´ë°ë¯¸")
            
        # ëŒ€ìƒ í•™ë…„ ì¶”ì¶œ
        if any(word in name for word in ["ì´ˆë“±", "ìœ ì•„", "ì–´ë¦°ì´"]):
            keywords.append("ì´ˆë“±í•™ì›")
        if "ì¤‘ë“±" in name or "ì¤‘í•™" in name:
            keywords.append("ì¤‘ë“±í•™ì›")
        if "ê³ ë“±" in name or "ì…ì‹œ" in name:
            keywords.append("ê³ ë“±í•™ì›")
            
        # ì§€ì—­ëª… ì¶”ì¶œ
        regions = ["ì¸ì²œ", "ì„œêµ¬", "ì²­ë¼", "ê²€ë‹¨", "ê²½ì„œ", "ê°€ì •", "ì„ë‚¨"]
        for region in regions:
            if region in name:
                keywords.append(f"{region}í•™ì›")
                break
        
        # íŠ¹ìˆ˜ í”„ë¡œê·¸ë¨
        if any(word in name for word in ["ì›ì–´ë¯¼", "í™”ìƒ", "ìŠ¤í”¼í‚¹"]):
            keywords.append("ì›ì–´ë¯¼ì˜ì–´")
        if "ë°©ê³¼í›„" in name:
            keywords.append("ë°©ê³¼í›„í•™ì›")
            
        # ì¤‘ë³µ ì œê±° ë° ìµœëŒ€ 8ê°œë¡œ ì œí•œ
        keywords = list(set(keywords))[:8]
        
        # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ê°€
        if not keywords:
            keywords = ["í•™ì›", "êµìœ¡", "í•™ìŠµ"]
        
        result.append({
            "businessName": name,
            "keywords": keywords
        })
    
    return result

# ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_related_keywords(api_response: Dict, original_keyword: str = "", limit: int = 10) -> List[Dict]:
    """ë„¤ì´ë²„ APIì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ (CTR í¬í•¨)"""
    try:
        if not api_response.get("success"):
            return []
        
        data = api_response.get("data", {})
        keywords = data.get("keywordList", [])
        
        if not keywords:
            return []
        
        # ìƒìœ„ Nê°œ í‚¤ì›Œë“œ ì¶”ì¶œ
        result = []
        for kw in keywords[:limit]:
            monthly_pc = kw.get("monthlyPcQcCnt", 0)
            monthly_mobile = kw.get("monthlyMobileQcCnt", 0)
            total_search = monthly_pc + monthly_mobile
            
            # CTR (í´ë¦­ë¥ ) ê³„ì‚°
            pc_ctr = kw.get("monthlyAvePcCtr", 0)
            mobile_ctr = kw.get("monthlyAveMobileCtr", 0)
            
            # ê°€ì¤‘ í‰ê·  CTR
            if total_search > 0:
                weighted_ctr = (pc_ctr * monthly_pc + mobile_ctr * monthly_mobile) / total_search
            else:
                weighted_ctr = 0
            
            # ê²½ìŸ ê°•ë„
            comp_idx = kw.get("compIdx", "01")
            comp_map = {
                "01": "ë‚®ìŒ",
                "02": "ë³´í†µ",
                "03": "ë†’ìŒ",
                "04": "ë§¤ìš° ë†’ìŒ"
            }
            competition = comp_map.get(comp_idx, "ë³´í†µ")
            
            result.append({
                "keyword": kw.get("relKeyword", ""),
                "monthlySearchVolume": total_search,
                "monthlyPcSearch": monthly_pc,
                "monthlyMobileSearch": monthly_mobile,
                "averageCtr": round(weighted_ctr, 2),  # í‰ê·  í´ë¦­ë¥  (%)
                "pcCtr": round(pc_ctr, 2),
                "mobileCtr": round(mobile_ctr, 2),
                "competition": competition
            })
        
        return result
        
    except Exception as e:
        print(f"ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        return []

# ê²€ìƒ‰ëŸ‰ ë°ì´í„° íŒŒì‹± (í™•ì¥ ë²„ì „)
def parse_search_volume_extended(api_response: Dict, original_keyword: str = "") -> Dict:
    """ë„¤ì´ë²„ API ì‘ë‹µì—ì„œ ê²€ìƒ‰ëŸ‰ + CTR ë°ì´í„° íŒŒì‹±"""
    try:
        if not api_response.get("success"):
            return {
                "monthlyAvg": 0,
                "monthlyPcSearch": 0,
                "monthlyMobileSearch": 0,
                "averageCtr": 0,
                "pcCtr": 0,
                "mobileCtr": 0,
                "competition": "ì•Œ ìˆ˜ ì—†ìŒ",
                "recommendation": "ë¶„ì„ì¤‘"
            }
        
        data = api_response.get("data", {})
        keywords = data.get("keywordList", [])
        
        if not keywords:
            return {
                "monthlyAvg": 0,
                "monthlyPcSearch": 0,
                "monthlyMobileSearch": 0,
                "averageCtr": 0,
                "pcCtr": 0,
                "mobileCtr": 0,
                "competition": "ë‚®ìŒ",
                "recommendation": "ë°ì´í„° ì—†ìŒ"
            }
        
        # ì›ë³¸ í‚¤ì›Œë“œì™€ ê°€ì¥ ìœ ì‚¬í•œ í‚¤ì›Œë“œ ì°¾ê¸°
        keyword_data = keywords[0]  # ê¸°ë³¸ê°’
        
        if original_keyword:
            # ì§€ì—­ëª… ì œê±°
            regions = ["ì¸ì²œ", "ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ëŒ€ì „", "ê´‘ì£¼", "ìš¸ì‚°", "ì„¸ì¢…", "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼",
                       "ì„œêµ¬", "ë¶êµ¬", "ë™êµ¬", "ë‚¨êµ¬", "ì¤‘êµ¬", "ì²­ë¼", "ê²€ë‹¨", "ì†¡ë„", "ê°•ë‚¨", "ê°•ë¶", "ì„œì´ˆ", "ì¢…ë¡œ", "ë§ˆí¬", "ê°•ì„œ", "í•´ìš´ëŒ€"]
            core_original = original_keyword
            for region in regions:
                core_original = core_original.replace(region + " ", "").replace(region, "")
            core_original = core_original.strip()
            
            # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
            for kw in keywords:
                if kw.get("relKeyword", "").strip() == core_original:
                    keyword_data = kw
                    break
            else:
                # ë¶€ë¶„ ì¼ì¹˜ ì°¾ê¸°
                for kw in keywords:
                    if core_original in kw.get("relKeyword", "") or kw.get("relKeyword", "") in core_original:
                        keyword_data = kw
                        break
        
        monthly_pc = keyword_data.get("monthlyPcQcCnt", 0)
        monthly_mobile = keyword_data.get("monthlyMobileQcCnt", 0)
        monthly_avg = monthly_pc + monthly_mobile
        
        # CTR ë°ì´í„°
        pc_ctr = keyword_data.get("monthlyAvePcCtr", 0)
        mobile_ctr = keyword_data.get("monthlyAveMobileCtr", 0)
        
        # ê°€ì¤‘ í‰ê·  CTR
        if monthly_avg > 0:
            weighted_ctr = (pc_ctr * monthly_pc + mobile_ctr * monthly_mobile) / monthly_avg
        else:
            weighted_ctr = 0
        
        comp_idx = keyword_data.get("compIdx", "01")
        
        # ê²½ìŸ ê°•ë„ íŒë‹¨
        comp_map = {
            "01": "ë‚®ìŒ",
            "02": "ë³´í†µ",
            "03": "ë†’ìŒ",
            "04": "ë§¤ìš° ë†’ìŒ"
        }
        competition = comp_map.get(comp_idx, "ë³´í†µ")
        
        # ì¶”ì²œë„ íŒë‹¨
        if monthly_avg >= 1000 and comp_idx in ["01", "02"]:
            recommendation = "ì ê·¹ ì¶”ì²œ"
        elif monthly_avg >= 500:
            recommendation = "ì¶”ì²œ"
        elif monthly_avg >= 100:
            recommendation = "ë³´í†µ"
        else:
            recommendation = "ë‚®ì€ ê²€ìƒ‰ëŸ‰"
        
        return {
            "monthlyAvg": monthly_avg,
            "monthlyPcSearch": monthly_pc,
            "monthlyMobileSearch": monthly_mobile,
            "averageCtr": round(weighted_ctr, 2),
            "pcCtr": round(pc_ctr, 2),
            "mobileCtr": round(mobile_ctr, 2),
            "competition": competition,
            "recommendation": recommendation
        }
        
    except Exception as e:
        print(f"ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return {
            "monthlyAvg": 0,
            "monthlyPcSearch": 0,
            "monthlyMobileSearch": 0,
            "averageCtr": 0,
            "pcCtr": 0,
            "mobileCtr": 0,
            "competition": "ì•Œ ìˆ˜ ì—†ìŒ",
            "recommendation": "ì˜¤ë¥˜ ë°œìƒ"
        }

# ê²€ìƒ‰ëŸ‰ ë°ì´í„° íŒŒì‹±
def parse_search_volume(api_response: Dict, original_keyword: str = "") -> Dict:
    """ë„¤ì´ë²„ API ì‘ë‹µì—ì„œ ê²€ìƒ‰ëŸ‰ ë°ì´í„° íŒŒì‹±"""
    try:
        if not api_response.get("success"):
            return {
                "monthlyAvg": 0,
                "competition": "ì•Œ ìˆ˜ ì—†ìŒ",
                "recommendation": "ë¶„ì„ì¤‘"
            }
        
        data = api_response.get("data", {})
        keywords = data.get("keywordList", [])
        
        if not keywords:
            return {
                "monthlyAvg": 0,
                "competition": "ë‚®ìŒ",
                "recommendation": "ë°ì´í„° ì—†ìŒ"
            }
        
        # ì›ë³¸ í‚¤ì›Œë“œì™€ ê°€ì¥ ìœ ì‚¬í•œ í‚¤ì›Œë“œ ì°¾ê¸°
        keyword_data = keywords[0]  # ê¸°ë³¸ê°’
        
        if original_keyword:
            # ì§€ì—­ëª… ì œê±°
            regions = ["ì¸ì²œ", "ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ëŒ€ì „", "ê´‘ì£¼", "ìš¸ì‚°", "ì„¸ì¢…", "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼",
                       "ì„œêµ¬", "ë¶êµ¬", "ë™êµ¬", "ë‚¨êµ¬", "ì¤‘êµ¬", "ì²­ë¼", "ê²€ë‹¨", "ì†¡ë„", "ê°•ë‚¨", "ê°•ë¶", "ì„œì´ˆ", "ì¢…ë¡œ", "ë§ˆí¬", "ê°•ì„œ", "í•´ìš´ëŒ€"]
            core_original = original_keyword
            for region in regions:
                core_original = core_original.replace(region + " ", "").replace(region, "")
            core_original = core_original.strip()
            
            print(f"ğŸ” ì›ë³¸ í‚¤ì›Œë“œ: {original_keyword} â†’ í•µì‹¬: {core_original}")
            
            # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
            for kw in keywords:
                if kw.get("relKeyword", "").strip() == core_original:
                    keyword_data = kw
                    print(f"âœ… ì •í™• ì¼ì¹˜: {kw.get('relKeyword')}")
                    break
            else:
                # ë¶€ë¶„ ì¼ì¹˜ ì°¾ê¸°
                for kw in keywords:
                    if core_original in kw.get("relKeyword", "") or kw.get("relKeyword", "") in core_original:
                        keyword_data = kw
                        print(f"âœ… ë¶€ë¶„ ì¼ì¹˜: {kw.get('relKeyword')}")
                        break
                else:
                    print(f"âš ï¸  ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œ ì—†ìŒ, ì²« ë²ˆì§¸ ì‚¬ìš©: {keywords[0].get('relKeyword')}")
        
        monthly_avg = keyword_data.get("monthlyPcQcCnt", 0) + keyword_data.get("monthlyMobileQcCnt", 0)
        comp_idx = keyword_data.get("compIdx", "01")
        
        # ê²½ìŸ ê°•ë„ íŒë‹¨
        comp_map = {
            "01": "ë‚®ìŒ",
            "02": "ë³´í†µ",
            "03": "ë†’ìŒ",
            "04": "ë§¤ìš° ë†’ìŒ"
        }
        competition = comp_map.get(comp_idx, "ë³´í†µ")
        
        # ì¶”ì²œë„ íŒë‹¨
        if monthly_avg >= 1000 and comp_idx in ["01", "02"]:
            recommendation = "ì ê·¹ ì¶”ì²œ"
        elif monthly_avg >= 500:
            recommendation = "ì¶”ì²œ"
        elif monthly_avg >= 100:
            recommendation = "ë³´í†µ"
        else:
            recommendation = "ë‚®ì€ ê²€ìƒ‰ëŸ‰"
        
        return {
            "monthlyAvg": monthly_avg,
            "competition": competition,
            "recommendation": recommendation
        }
        
    except Exception as e:
        print(f"ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return {
            "monthlyAvg": 0,
            "competition": "ì•Œ ìˆ˜ ì—†ìŒ",
            "recommendation": "ì˜¤ë¥˜ ë°œìƒ"
        }

@app.get("/", response_model=HealthResponse)
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "message": "Naver Crawler API is running"
    }

@app.post("/analyze")
async def analyze_keyword(request: SearchAnalysisRequest):
    """í‚¤ì›Œë“œ ë¶„ì„ (ê²€ìƒ‰ëŸ‰ + ìˆœìœ„)"""
    try:
        keyword = request.keyword
        place_url = request.placeUrl
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ë¶„ì„ ì‹œì‘: {keyword}")
        print(f"ğŸ“ í”Œë ˆì´ìŠ¤ URL: {place_url if place_url else 'ë¯¸ì…ë ¥'}")
        print(f"{'='*60}\n")
        
        # 1. ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  APIë¡œ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ
        print(f"ğŸ” 1ë‹¨ê³„: ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API í˜¸ì¶œ ì¤‘...")
        api_response = call_naver_api(keyword)
        print(f"âœ… API ì‘ë‹µ: success={api_response.get('success')}")
        
        # í™•ì¥ ë²„ì „ (CTR í¬í•¨)
        search_volume_extended = parse_search_volume_extended(api_response, keyword)
        print(f"ğŸ“ˆ ê²€ìƒ‰ëŸ‰: {search_volume_extended.get('monthlyAvg')}, ê²½ìŸë„: {search_volume_extended.get('competition')}, í‰ê·  CTR: {search_volume_extended.get('averageCtr')}%")
        
        # ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ (10ê°œ)
        related_keywords = extract_related_keywords(api_response, keyword, limit=10)
        print(f"ğŸ”‘ ê´€ë ¨ í‚¤ì›Œë“œ: {len(related_keywords)}ê°œ ë°œê²¬")
        
        # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ê°„ë‹¨í•œ ë²„ì „
        search_volume = parse_search_volume(api_response, keyword)
        print(f"ğŸ“ˆ ê²€ìƒ‰ëŸ‰: {search_volume.get('monthlyAvg')}, ê²½ìŸë„: {search_volume.get('competition')}")
        
        # 2. BeautifulSoupìœ¼ë¡œ í”Œë ˆì´ìŠ¤ ìˆœìœ„ í¬ë¡¤ë§
        print(f"\nğŸ•·ï¸  2ë‹¨ê³„: í”Œë ˆì´ìŠ¤ ìˆœìœ„ í¬ë¡¤ë§ ì¤‘...")
        ranking_data = crawl_place_ranking(keyword, place_url)
        print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(ranking_data.get('competitors', []))}ê°œ ì—…ì²´ ë°œê²¬")
        
        # 3. ê²½ìŸì‚¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        print(f"\nğŸ”‘ 3ë‹¨ê³„: ê²½ìŸì‚¬ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
        competitors = ranking_data.get("competitors", [])
        keywords = extract_competitor_keywords(competitors)
        print(f"âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ: {len(keywords)}ê°œ ì—…ì²´")
        
        print(f"\n{'='*60}")
        print(f"âœ… ë¶„ì„ ì™„ë£Œ!")
        print(f"{'='*60}\n")
        
        return {
            "success": True,
            "searchVolume": search_volume,
            "searchVolumeExtended": search_volume_extended,  # CTR í¬í•¨
            "relatedKeywords": related_keywords,  # ê´€ë ¨ í‚¤ì›Œë“œ
            "ranking": {
                "myRank": ranking_data.get("myRank"),
                "competitors": competitors
            },
            "keywords": keywords
        }
        
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/test-api")
async def test_naver_api():
    """ë„¤ì´ë²„ API í…ŒìŠ¤íŠ¸"""
    result = call_naver_api("ì˜ì–´í•™ì›")
    return result

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
